{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the OpenCV library for image and video processing.\n",
    "import cv2\n",
    "\n",
    "# Import the os library to interact with the operating system, such as file paths and directories.\n",
    "import os\n",
    "\n",
    "# Import the MediaPipe library for hand tracking and gesture recognition.\n",
    "import mediapipe as mp\n",
    "\n",
    "# Import display, Image, and clear_output functions from IPython.display to handle image output in Jupyter Notebook.\n",
    "from IPython.display import display, Image, clear_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path where collected images will be stored. \n",
    "# This directory contains raw images collected for the sign language detection project.\n",
    "IMAGES_PATH = \"images/collected - Copy\"\n",
    "\n",
    "# Define the path where labeled images will be saved. \n",
    "# This directory is intended for images that have been processed and labeled for training the model.\n",
    "LABELED_IMAGES_PATH = \"images/labeled\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of dictionaries to store label information for hand signs.\n",
    "# Each dictionary contains a 'name' representing the sign gesture \n",
    "# and an 'id' that serves as a unique identifier for mapping purposes.\n",
    "label_info = [\n",
    "    {'name': 'hello', 'id': 1},       # Label for the 'hello' sign, assigned ID 1\n",
    "    {'name': 'thanks', 'id': 2},      # Label for the 'thanks' sign, assigned ID 2\n",
    "    {'name': 'yes', 'id': 3},         # Label for the 'yes' sign, assigned ID 3\n",
    "    {'name': 'no', 'id': 4},          # Label for the 'no' sign, assigned ID 4\n",
    "    {'name': 'iloveyou', 'id': 5}     # Label for the 'I love you' sign, assigned ID 5\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access the MediaPipe Hands module, which provides tools for hand tracking and gesture recognition.\n",
    "mp_hands = mp.solutions.hands\n",
    "\n",
    "# Initialize the Hands class with specified parameters for detection and tracking confidence.\n",
    "# min_detection_confidence sets the threshold for detecting hands, while min_tracking_confidence\n",
    "# controls the confidence level for tracking hands across frames.\n",
    "hands = mp_hands.Hands(min_detection_confidence=0.5, min_tracking_confidence=0.5)\n",
    "\n",
    "# Access the drawing utilities from MediaPipe to facilitate the visualization of hand landmarks and connections.\n",
    "mp_drawing = mp.solutions.drawing_utils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the directory for labeled images already exists.\n",
    "if not os.path.exists(LABELED_IMAGES_PATH):\n",
    "    # If the directory does not exist, create it to store labeled images.\n",
    "    os.makedirs(LABELED_IMAGES_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_bounding_box_with_label(frame, label_name):\n",
    "    \"\"\"\n",
    "    Draws a bounding box around detected hands and labels them as one.\n",
    "    \n",
    "    Parameters:\n",
    "    - frame: The image frame from the video stream where hand detection is performed.\n",
    "    - label_name: The label to be displayed above the bounding box, indicating the recognized gesture.\n",
    "    \n",
    "    Returns:\n",
    "    - The modified frame with the bounding box and label drawn on it.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Convert the BGR frame to RGB format, as MediaPipe expects RGB input.\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Process the RGB frame to detect hands and retrieve landmarks.\n",
    "    results = hands.process(rgb_frame)\n",
    "\n",
    "    # Check if any hands are detected in the frame.\n",
    "    if results.multi_hand_landmarks:\n",
    "        # Initialize bounding box coordinates to extremes for later adjustments.\n",
    "        x_min, y_min = frame.shape[1], frame.shape[0]  # Start with maximum values\n",
    "        x_max, y_max = 0, 0  # Start with minimum values\n",
    "        \n",
    "        # Iterate through each detected hand's landmarks.\n",
    "        for hand_landmarks in results.multi_hand_landmarks:\n",
    "            for landmark in hand_landmarks.landmark:\n",
    "                # Convert landmark coordinates from normalized values to pixel values.\n",
    "                x = int(landmark.x * frame.shape[1])\n",
    "                y = int(landmark.y * frame.shape[0])\n",
    "                \n",
    "                # Update bounding box coordinates based on the detected landmarks.\n",
    "                x_min = min(x_min, x)  # Find the leftmost point\n",
    "                y_min = min(y_min, y)  # Find the topmost point\n",
    "                x_max = max(x_max, x)  # Find the rightmost point\n",
    "                y_max = max(y_max, y)  # Find the bottommost point\n",
    "\n",
    "            # Draw the landmarks for the current hand on the frame.\n",
    "            mp_drawing.draw_landmarks(frame, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "\n",
    "        # Draw a bounding box around all detected hands combined.\n",
    "        cv2.rectangle(frame, (x_min, y_min), (x_max, y_max), (0, 255, 0), 2)  # Green box with thickness 2\n",
    "        \n",
    "        # Put the label above the bounding box.\n",
    "        cv2.putText(frame, label_name, (x_min, y_min - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "    # Return the modified frame with the drawn bounding box and label.\n",
    "    return frame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_images_with_bounding_boxes():\n",
    "    \"\"\"\n",
    "    Processes images for each label to add bounding boxes, labels, and save them.\n",
    "    This function iterates through all the labels defined in label_info, \n",
    "    reads the corresponding images, adds bounding boxes and labels, \n",
    "    and saves the modified images in a specified directory.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Loop through each label in the label_info list.\n",
    "    for label in label_info:\n",
    "        label_name = label['name']  # Get the name of the current label.\n",
    "        label_path = os.path.join(IMAGES_PATH, label_name)  # Construct the path for the raw images of this label.\n",
    "        labeled_label_path = os.path.join(LABELED_IMAGES_PATH, label_name)  # Construct the output path for labeled images.\n",
    "\n",
    "        # Ensure the output directory exists for the labeled images of the current label.\n",
    "        if not os.path.exists(labeled_label_path):\n",
    "            os.makedirs(labeled_label_path)\n",
    "\n",
    "        # Check if the directory for the raw images exists.\n",
    "        if not os.path.exists(label_path):\n",
    "            print(f\"Directory {label_path} not found, skipping.\")  # Log if the directory is missing.\n",
    "            continue  # Skip to the next label if the directory is not found.\n",
    "\n",
    "        # Loop through each image in the current label's directory.\n",
    "        for image_name in os.listdir(label_path):\n",
    "            image_path = os.path.join(label_path, image_name)  # Construct the full image path.\n",
    "            frame = cv2.imread(image_path)  # Read the image using OpenCV.\n",
    "            \n",
    "            # Check if the image was read successfully.\n",
    "            if frame is None:\n",
    "                print(f\"Could not read image {image_path}, skipping.\")  # Log if the image could not be read.\n",
    "                continue  # Skip to the next image if there was an error.\n",
    "\n",
    "            # Draw bounding box and label on the frame using the previously defined function.\n",
    "            frame_with_box = draw_bounding_box_with_label(frame, label_name)\n",
    "\n",
    "            # Construct the path for saving the labeled image.\n",
    "            labeled_image_path = os.path.join(labeled_label_path, image_name)\n",
    "            cv2.imwrite(labeled_image_path, frame_with_box)  # Save the labeled image to the specified path.\n",
    "            print(f\"Saved labeled image: {labeled_image_path}\")  # Log the successful save operation.\n",
    "\n",
    "            # Display the image in a Jupyter Notebook environment (optional).\n",
    "            try:\n",
    "                # Encode the image as JPEG for display.\n",
    "                _, jpeg = cv2.imencode('.jpg', frame_with_box)\n",
    "                display(Image(data=jpeg.tobytes()))  # Display the image.\n",
    "                clear_output(wait=True)  # Clear previous output to show the current image.\n",
    "            except:\n",
    "                pass  # Handle any exceptions, particularly in non-IPython environments.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to initialize and run the bounding box labeling process.\n",
    "    \"\"\"\n",
    "    print(\"Starting image processing for bounding box labeling and saving...\")\n",
    "    process_images_with_bounding_boxes()\n",
    "    print(\"Image processing and saving completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
